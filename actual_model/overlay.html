<!DOCTYPE html>
<html>

<script src="https://app.ohmnilabs.com/api/Ohmni-incall.js"></script>
<script src="js/volume_meter.js"></script>
<script src="js/audio_record.js"></script>
<script src="js/jquerymin.js"></script>
<script src="js/socket.js"></script>
<script src="js/model.js"></script>

<script src="node_modules/face-api.js/dist/face-api.min.js"></script>

<head>
    <meta charset="utf-8">
    <title>Display Webcam Stream</title>

    <style>
        .container {
            position: relative;
            text-align: center;
        }

        .video {
            width: 100%;
            height: auto;
            position: absolute;
            top: 0;
            left: 0;
        }

        .canvas {
            position: relative;
            z-index: 9;
            pointer-events: none;
            width: 1026px;
            height: 821px;
            text-align: center;
        }

        .buttons {
            z-index: 10;
            position: absolute;
            top: 0;
            left: 0;
        }

        body {
            margin: 0;
        }
    </style>
</head>

<body>
    <!-- used for face detector -->
    <div class="container">
        <canvas class="canvas" id="overlay"></canvas>
        <div class="buttons">
            <button type="button" id="startCaptureVideo" data-external="true" class="button"
                style="padding:30px;margin:20px; margin-top: 60px"
                onclick="captureVideo();">startCaptureVideo</button><br>
            <button type="button" id="stopCaptureVideo" data-external="true" class="button"
                style="padding:30px;margin:20px; margin-top: 60px; display: none;"
                onclick="stopCaptureVideo();">stopCaptureVideo</button><br>
            <img src="" id="videoCall" style="display: none;"> <br>
            <!-- audio sensing button -->
            <!-- <button onclick="loadAudioContext()" data-external="true">Start Audio Sensing</button> -->
        </div>
    </div>

    <!--Used for volume meter-->
    <div style="text-align: center;">
        <img src="https://api.ohmnilabs.com/ohmni-api/test-incall.html" width="100%" height="100%" hidden id="videoCall"
            style="display: none;"> <br>

        <!--Used for volume meter-->
        <div hidden class="unclickable">
            <canvas id="meter" width="500" height="50"></canvas>
        </div>
        <div hidden class="slidecontainer">
            <input hidden type="range" min="0" max="1" value="0.5" step="0.01" class="slider" id="myRange">
        </div>
        <div class="slidecontainer">
            <input hidden type="range" min="0" max="1" value="0.5" step="0.01" class="slider" id="myRange2">
        </div>
        <div class="slidecontainer">
            <input hidden type="range" min="0" max="1" value="0.5" step="0.01" class="slider" id="myRange3">
        </div>
        <div class="slidecontainer">
            <input hidden type="range" min="0" max="1000" value="500" step="10" class="slider" id="myRange4">
        </div>
    </div>

    <!--SCRIPT-->
    <script>
        // set up websocket connection

        $(document).ready(function () {
            setUpWebSocket();
            console.log("finished set up websocket");
            setGlobals();
            console.log("finished set up globals");
        });

        function setGlobals() {
            canvas = document.getElementById('overlay');
            ctx = canvas.getContext('2d');
            volume_set = false;
            videoCallBackWidth = 1026;
            videoCallBackHeight = 821;
            detections = [];
            options = new faceapi.SsdMobilenetv1Options({ minConfidence: 0.3, maxResults: 10 });

            img_circle = new Image();
            img_check = new Image();

            img_circle.src = "https://nri-kids-interaction-lab.github.io/actual_model/images/gray-circle.png";
            img_check.src = "https://nri-kids-interaction-lab.github.io/actual_model/images/green-check.jpg";

            circ_loaded = false;
            check_loaded = false;

            img_circle.onload = function(){
                circ_loaded = true;
                console.log("circle img loaded");
            }
            img_check.onload = function(){
                check_loaded = true;
                console.log("check img loaded");
            }

        }

        // ohmni code
        function captureVideo() {
            // start audio recording
            startAudioRecorder(); 

            // face detector
            modelLoaded = false;
            Ohmni.captureVideo(videoCallBackWidth, videoCallBackHeight);
            
            setInterval(function() {
                drawLoop();
            }, 500);

            document.getElementById('stopCaptureVideo').style.display = "inline-block";
            document.getElementById('startCaptureVideo').style.display = "none";
        }

        function stopCaptureVideo() {
            document.getElementById('startCaptureVideo').style.display = "inline-block";
            document.getElementById('stopCaptureVideo').style.display = "none";
        }
        const sleep = (milliseconds) => {
            return new Promise(resolve => setTimeout(resolve, milliseconds))
        }

        async function captureVideoCb(imageBase64) {
            document.getElementById("videoCall").src = imageBase64;
            await runFaceDetection();
            Ohmni.captureVideo(videoCallBackWidth, videoCallBackHeight);
        }
        // Canvas code
        function getCenterFromWH(width, height) {
            return [(canvas.width - width) / 2.0, (canvas.height - height) / 2.0 - 200]
        }
        function getStrokeColor(color) {
            var frequency = .3;
            var red = Math.floor(Math.sin(frequency * color + 0) * 127 + 128);
            var green = Math.floor(Math.sin(frequency * color + 2) * 127 + 128);
            var blue = Math.floor(Math.sin(frequency * color + 4) * 127 + 128);
            return "#" +
                red.toString(16) +
                green.toString(16) +
                blue.toString(16);
        }
        function drawSquare(x, y, w, h, thickness, strokeColor) {
            ctx.beginPath();
            ctx.lineWidth = thickness;
            ctx.strokeStyle = strokeColor;
            ctx.rect(x, y, w, h);
            ctx.stroke();
        }

        async function loadModel() {
            const MODEL_URL = 'weights';
            console.log("model loading");
            await faceapi.nets.ssdMobilenetv1.loadFromUri(MODEL_URL);
            console.log("model loaded");
            canvas = document.getElementById('overlay');
            input = document.getElementById('videoCall');
            displaySize = { width: canvas.width, height: canvas.height }
            faceapi.matchDimensions(canvas, displaySize);
            console.log("Face detection loaded, looping detection");
            modelLoaded = true;
        }

        async function runFaceDetection() {
            if (!modelLoaded) {
                await loadModel();
            }
            detections = await faceapi.detectAllFaces(input, options);
        }

        function drawLoop(){
            if(!circ_loaded || !check_loaded){
                return;
            }

            ctx.clearRect(0, 0, canvas.width, canvas.height);
            for (var i = detections.length - 1; i >= 0; --i) {
                var ad = adjustBox(detections[i]._box);
                //var color = "#FF0000"

                // ************ temporary model logic **************
                // Should this be getting box height or adjusted?
                if(applyVoiceModel(detections[i]._box._height)) {
                  //  color = "#008000";
                    ctx.drawImage(img_check, ad[0], ad[1], ad[2], ad[3]);
                }
                else{
                    ctx.drawImage(img_circle, ad[0],ad[1], ad[2], ad[3]);
                }
                //drawSquare(ad[0], ad[1], ad[2], ad[3], 1, color);
                // ************ temporary model logic **************
            }
            if (detections.length == 0) {
                console.log("No detections found")
            }
        }

        // Returns [X,Y,W,H] adjusted
        function adjustBox(box) {
            var xfac = box._x / videoCallBackWidth * canvas.width;
            var yfac = box._y / videoCallBackHeight * canvas.height;
            var wfac = box._width / videoCallBackWidth * canvas.width;
            var hfac = box._height / videoCallBackHeight * canvas.height;
            return [xfac, yfac, wfac, hfac];
        }


    </script>
</body>

</html>